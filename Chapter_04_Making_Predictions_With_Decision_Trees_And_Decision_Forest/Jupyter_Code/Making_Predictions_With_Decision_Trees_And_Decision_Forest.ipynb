{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spark = SparkSession.builder.config(\"spark.driver.memory\", \"8g\").appName(\"DecisionTree\").getOrCreate()",
   "id": "39a578b5565b310",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preparing the Data",
   "id": "ee7e8ab484f1891c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_without_header = spark.read.option(\"inferSchema\", True)\\\n",
    "                      .option(\"header\", False).csv(\"data/covtype.data\")\n",
    "\n",
    "data_without_header.printSchema()"
   ],
   "id": "81c6bdec33dcb05b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "colnames = [\n",
    "    \"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\"\n",
    "] + \\\n",
    "    [f\"Wilderness_Area_{i}\" for i in range(4)] + \\\n",
    "    [f\"Soil_Type_{i}\" for i in range(40)] + \\\n",
    "    [\"Cover_Type\"]\n",
    "\n",
    "data = data_without_header.toDF(*colnames). \\\n",
    "    withColumn(\"Cover_Type\", col(\"Cover_Type\").cast(DoubleType()))\n",
    "\n",
    "data.head()"
   ],
   "id": "9b431b55a2ce38f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Our First Decision Tree",
   "id": "eaf3bf158b2856bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "(train_data, test_data) = data.randomSplit([0.9, 0.1])\n",
    "train_data.cache()\n",
    "test_data.cache()"
   ],
   "id": "b8d162ec5868581d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "input_cols = colnames[:-1]\n",
    "vector_assembler = VectorAssembler(inputCols=input_cols, outputCol=\"featureVector\")\n",
    "\n",
    "assembled_train_data = vector_assembler.transform(train_data)\n",
    "\n",
    "assembled_train_data.select(\"featureVector\").show(truncate = False)"
   ],
   "id": "e6ea28c9260b7692"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(seed=1234, labelCol=\"Cover_Type\", featuresCol=\"featureVector\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "\n",
    "model = classifier.fit(assembled_train_data)\n",
    "print(model.toDebugString)"
   ],
   "id": "93c32205d8c8395a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(model.featureImportances.toArray(), \n",
    "             index=input_cols, columns=[\"importance\"]). \\\n",
    "    sort_values(by=\"importance\", ascending=False)"
   ],
   "id": "6503ea82e38b6e0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictions = model.transform(assembled_train_data)\n",
    "predictions.select(\"Cover_Type\", \"prediction\", \"probability\").show(10, truncate=False)"
   ],
   "id": "3e4b1e6d20c6b243"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Cover_Type\",\n",
    "                                        predictionCol=\"prediction\")\n",
    "\n",
    "evaluator.setMetricName(\"accuracy\").evaluate(predictions)\n",
    "evaluator.setMetricName(\"f1\").evaluate(predictions)"
   ],
   "id": "1837c3243b765073"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "confusion_matrix = predictions.groupBy(\"Cover_Type\").\\\n",
    "    pivot(\"prediction\", range(1,8)).count().\\\n",
    "    na.fill(0.0).\\\n",
    "    orderBy(\"Cover_Type\")\n",
    "\n",
    "confusion_matrix.show()"
   ],
   "id": "3efb226282cd57cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def class_probabilities(data):\n",
    "    total = data.count()\n",
    "    return data.groupBy(\"Cover_Type\").count(). \\\n",
    "        orderBy(\"Cover_Type\"). \\\n",
    "        select(col(\"count\").cast(DoubleType())). \\\n",
    "        withColumn(\"count_proportion\", col(\"count\") / total). \\\n",
    "        select(\"count_proportion\").collect()\n",
    "\n",
    "\n",
    "train_prior_probabilities = class_probabilities(train_data)\n",
    "test_prior_probabilities = class_probabilities(test_data)\n",
    "\n",
    "train_prior_probabilities"
   ],
   "id": "41481e7975873267"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_prior_probabilities = [p[0] for p in train_prior_probabilities]\n",
    "test_prior_probabilities = [p[0] for p in test_prior_probabilities]\n",
    "\n",
    "sum([train_p * cv_p for train_p, cv_p in zip(train_prior_probabilities, test_prior_probabilities)])"
   ],
   "id": "9460adff18f5575e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tuning Decision Tress",
   "id": "d8abd68c351c0b97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "assembler = VectorAssembler(inputCols=input_cols, outputCol=\"featureVector\")\n",
    "classifier = DecisionTreeClassifier(seed=1234, labelCol=\"Cover_Type\",\n",
    "                                    featuresCol=\"featureVector\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, classifier])"
   ],
   "id": "92cbef4f4904e8e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "paramGrid = ParamGridBuilder(). \\\n",
    "    addGrid(classifier.impurity, [\"gini\", \"entropy\"]). \\\n",
    "    addGrid(classifier.maxDepth, [1, 20]). \\\n",
    "    addGrid(classifier.maxBins, [40, 300]). \\\n",
    "    addGrid(classifier.minInfoGain, [0.0, 0.05]). \\\n",
    "    build()\n",
    "\n",
    "multiclassEval = MulticlassClassificationEvaluator(). \\\n",
    "    setLabelCol(\"Cover_Type\"). \\\n",
    "    setPredictionCol(\"prediction\"). \\\n",
    "    setMetricName(\"accuracy\")"
   ],
   "id": "f54778e3150ff71c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "\n",
    "validator = TrainValidationSplit(seed=1234,\n",
    "                                 estimator=pipeline,\n",
    "                                 evaluator=multiclassEval,\n",
    "                                 estimatorParamMaps=paramGrid,\n",
    "                                 trainRatio=0.9)\n",
    "\n",
    "validator_model = validator.fit(train_data)"
   ],
   "id": "ea411222dd51796d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pprint import pprint\n",
    "\n",
    "best_model = validator_model.bestModel\n",
    "pprint(best_model.stages[1].extractParamMap())"
   ],
   "id": "a8606ba2f09c08da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "validator_model = validator.fit(train_data)\n",
    "\n",
    "metrics = validator_model.validationMetrics\n",
    "params = validator_model.getEstimatorParamMaps()\n",
    "metrics_and_params = list(zip(metrics, params))\n",
    "\n",
    "metrics_and_params.sort(key=lambda x: x[0], reverse=True)\n",
    "metrics_and_params"
   ],
   "id": "d07127bda9410437"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "metrics.sort(reverse=True)\n",
    "print(metrics[0])"
   ],
   "id": "914b526eea032120"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "multiclassEval.evaluate(best_model.transform(test_data))",
   "id": "dd593680652f1e31"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Categorical Features Revisited",
   "id": "a107f8447b4999b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def unencode_one_hot(data):\n",
    "    wilderness_cols = ['Wilderness_Area_' + str(i) for i in range(4)]\n",
    "    wilderness_assembler = VectorAssembler(). \\\n",
    "                            setInputCols(wilderness_cols). \\\n",
    "                            setOutputCol(\"wilderness\")\n",
    "\n",
    "    unhot_udf = udf(lambda v: v.toArray().tolist().index(1))\n",
    "\n",
    "    with_wilderness = wilderness_assembler.transform(data). \\\n",
    "      drop(*wilderness_cols). \\\n",
    "      withColumn(\"wilderness\", unhot_udf(col(\"wilderness\")).cast(IntegerType()))\n",
    "\n",
    "    soil_cols = ['Soil_Type_' + str(i) for i in range(40)]\n",
    "    soil_assembler = VectorAssembler(). \\\n",
    "                      setInputCols(soil_cols). \\\n",
    "                      setOutputCol(\"soil\")\n",
    "    with_soil = soil_assembler. \\\n",
    "                transform(with_wilderness). \\\n",
    "                drop(*soil_cols). \\\n",
    "                withColumn(\"soil\", unhot_udf(col(\"soil\")).cast(IntegerType()))\n",
    "\n",
    "    return with_soil"
   ],
   "id": "f5fa7c76bdb307c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "unenc_train_data = unencode_one_hot(train_data)\n",
    "unenc_train_data.printSchema()"
   ],
   "id": "ab064ad44ae1d617"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "unenc_train_data.groupBy('wilderness').count().show()",
   "id": "fd306be94416ede"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.ml.feature import VectorIndexer\n",
    "\n",
    "cols = unenc_train_data.columns\n",
    "input_cols = [c for c in cols if c!='Cover_Type']\n",
    "\n",
    "assembler = VectorAssembler().setInputCols(input_cols).setOutputCol(\"featureVector\")\n",
    "\n",
    "indexer = VectorIndexer(). \\\n",
    "    setMaxCategories(40). \\\n",
    "    setInputCol(\"featureVector\"). \\\n",
    "    setOutputCol(\"indexedVector\")\n",
    "\n",
    "classifier = DecisionTreeClassifier(). \\\n",
    "    setLabelCol(\"Cover_Type\"). \\\n",
    "    setFeaturesCol(\"indexedVector\"). \\\n",
    "    setPredictionCol(\"prediction\")\n",
    "\n",
    "pipeline = Pipeline().setStages([assembler, indexer, classifier])"
   ],
   "id": "695931ac1a6b8b62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Random Forests",
   "id": "c00f5c03a758ec1b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(seed=1234, labelCol=\"Cover_Type\",\n",
    "                                    featuresCol=\"indexedVector\",\n",
    "                                    predictionCol=\"prediction\")"
   ],
   "id": "b24ffa772a49b2d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "unenc_train_data.columns",
   "id": "325fce6697a40c06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Skipped in book\n",
    "\n",
    "cols = unenc_train_data.columns\n",
    "input_cols = [c for c in cols if c!='Cover_Type']\n",
    "\n",
    "assembler = VectorAssembler().setInputCols(input_cols).setOutputCol(\"featureVector\")\n",
    "\n",
    "indexer = VectorIndexer(). \\\n",
    "    setMaxCategories(40). \\\n",
    "    setInputCol(\"featureVector\"). \\\n",
    "    setOutputCol(\"indexedVector\")\n",
    "\n",
    "pipeline = Pipeline().setStages([assembler, indexer, classifier])\n",
    "\n",
    "paramGrid = ParamGridBuilder(). \\\n",
    "    addGrid(classifier.impurity, [\"gini\", \"entropy\"]). \\\n",
    "    addGrid(classifier.maxDepth, [1, 20]). \\\n",
    "    addGrid(classifier.maxBins, [40, 300]). \\\n",
    "    addGrid(classifier.minInfoGain, [0.0, 0.05]). \\\n",
    "    build()\n",
    "\n",
    "multiclassEval = MulticlassClassificationEvaluator(). \\\n",
    "    setLabelCol(\"Cover_Type\"). \\\n",
    "    setPredictionCol(\"prediction\"). \\\n",
    "    setMetricName(\"accuracy\")\n",
    "\n",
    "validator = TrainValidationSplit(seed=1234,\n",
    "  estimator=pipeline,\n",
    "  evaluator=multiclassEval,\n",
    "  estimatorParamMaps=paramGrid,\n",
    "  trainRatio=0.9)\n",
    "\n",
    "validator_model = validator.fit(unenc_train_data)\n",
    "\n",
    "best_model = validator_model.bestModel"
   ],
   "id": "7928f80a94ed9622"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "forest_model = best_model.stages[2]\n",
    "\n",
    "feature_importance_list = list(zip(input_cols,\n",
    "                                  forest_model.featureImportances.toArray()))\n",
    "feature_importance_list.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "pprint(feature_importance_list)"
   ],
   "id": "efd438a4a547043e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Making Predictions",
   "id": "e83aa6e91ea48f7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "unenc_test_data = unencode_one_hot(test_data)\n",
    "\n",
    "best_model.transform(unenc_test_data.drop(\"Cover_Type\")).\\\n",
    "                    select(\"prediction\").show(1)"
   ],
   "id": "6871f6142e637c84"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
